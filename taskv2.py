# -*- coding: utf-8 -*-
"""taskv2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mp-qYvSkA1Z0R4u0cUz8c5eS3cc772iA
"""

!pip install opendatasets pandas -q

import opendatasets as od
import pandas
#{"username":"khwrali","key":"a2b23dfbac2443ab4db34e48318ce4ff"}
od.download(
    "https://www.kaggle.com/datasets/sripaadsrinivasan/audio-mnist")

import os
import librosa
import numpy as np
from tqdm import tqdm

data_folder = '/content/audio-mnist/data'

def extract_mfccs(file_path, num_mfcc=13):
    audio, sr = librosa.load(file_path, sr=None)
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=num_mfcc)
    return mfccs

num_mfcc = 13
num_instances = 50
num_speakers = 60
num_digits = 10

fixed_length = 100

mfccs_data = []
labels = []

for speaker_id in tqdm(range(1, num_speakers + 1), desc='Speakers'):
    speaker_folder = os.path.join(data_folder, f'{speaker_id:02d}')

    for digit in range(num_digits):
        for instance in tqdm(range(num_instances), desc=f'Digit {digit}'):
            file_name = f'{digit}_{speaker_id:02d}_{instance}.wav'
            file_path = os.path.join(speaker_folder, file_name)
            mfccs = extract_mfccs(file_path, num_mfcc)
            if mfccs.shape[1] < fixed_length:
                mfccs = np.pad(mfccs, ((0, 0), (0, fixed_length - mfccs.shape[1])))
            else:
                mfccs = mfccs[:, :fixed_length]

            mfccs_data.append(mfccs)
            labels.append(digit)

mfccs_data = np.array(mfccs_data)
labels = np.array(labels)
print("MFCCs shape:", mfccs_data.shape)
print("Labels shape:", labels.shape)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    mfccs_data, labels, test_size=0.1, random_state=42, stratify=labels
)

print("Train set shapes:", X_train.shape, y_train.shape)
print("Test set shapes:", X_test.shape, y_test.shape)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential()
model.add(LSTM(128, input_shape=(13, 100)))
model.add(Dense(10, activation='softmax'))


model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])


history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test accuracy:", test_accuracy)

predictions = model.predict(X_test)

print(X_test[0].shape)
print(np.argmax(predictions[0]))

